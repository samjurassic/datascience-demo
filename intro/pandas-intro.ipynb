{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Workshop: Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome! Here you will find a crash course in Python aimed at researchers and anyone else who works with data.\n",
    "\n",
    "This is a Jupyter Notebook - it allows you to run Python code, write text and tables in Markdown, and view image and other outputs. This is especially useful for exploratory data analysis, developing machine learning models, and any other interactive tasks where you want to run code in sections or iterate on your work without running a whole program.\n",
    "\n",
    "Some helpful keyboard shortcuts for working in Jupyter notebooks: https://digitalhumanities.hkust.edu.hk/tutorials/jupyter-notebook-tips-and-shortcuts/\n",
    "\n",
    "We will be focusing on common data manipulation tasks in Pandas, this focuses on solutions without too many low-level details, so be sure to check out the documentation if you want to learn more about the underlying functionality: https://pandas.pydata.org/docs/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # data frames, tabular data read/write\n",
    "import numpy as np  # linear algebra, math functions\n",
    "import seaborn as sns  # plotting\n",
    "\n",
    "from datetime import (\n",
    "    datetime,\n",
    ")  # we are only importing the datetime class from the datetime library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types and Variables (this is a markdown cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a comment (this is a code cell)\n",
    "\n",
    "\"\"\"\n",
    "This is a multi-line\n",
    "comment\n",
    "\"\"\"\n",
    "\n",
    "# types of variables\n",
    "\n",
    "# integer\n",
    "a = 3\n",
    "# float (up to 64-bit)\n",
    "b = 2.55\n",
    "# string\n",
    "d = \"boat\"\n",
    "# boolean (True, False) ~ (1, 0)\n",
    "f = True\n",
    "g = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intro to DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basics\n",
    "important_data = {\n",
    "    \"name\": [\"dom\", \"brian\", \"mia\", \"han\"],\n",
    "    \"car\": [\"charger\", \"skyline\", \"integra\", \"RX-7\"],\n",
    "    \"how_fast\": [7, 8, 5, 9],\n",
    "    \"how_furious\": [9, 3, 4, 2],\n",
    "}\n",
    "\n",
    "# this is a data frame, you can fill it with any data that is table-like\n",
    "important_df = pd.DataFrame(important_data)\n",
    "\n",
    "important_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data frames are objects with many METHODS, these are functions we access like: df.method()\n",
    "\n",
    "# describe returns summary statistics for numeric types\n",
    "important_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is a built-in plotting method...\n",
    "important_df.plot(\n",
    "    x=\"name\", kind=\"bar\", title=\"The disposition of various family members\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data frames also have many ATTRIBUTES, these are data, not functions, so no parentheses: df.attribute\n",
    "important_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns can be accessed with square brackets or attribute notation\n",
    "print(important_df[\"name\"])\n",
    "print(important_df.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data from a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DATA.gov provides open source government data from Federal, State, County, and City agencies\n",
    "\n",
    "Let's take a look at a dataset from the Consumer Financial Protection Bureau\n",
    "\n",
    "https://catalog.data.gov/dataset/college-credit-card-marketing-agreements-data\n",
    "\n",
    "As required by the Credit CARD Act of 2009, we collect information annually from credit card issuers who\n",
    "have marketing agreements with universities, colleges, or affiliated organizations such as alumni associations,\n",
    "sororities, fraternities, and foundations.\n",
    "\n",
    "Data dictionary: https://files.consumerfinance.gov/f/documents/cfpb_college-credit-card-data-guide_2022.pdf\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# you can use a URL to a file or a file path on your computer\n",
    "file_location = \"https://files.consumerfinance.gov/f/documents/cfpb_college-credit-card-agreements-database-2009-2019.csv\"\n",
    "\n",
    "# read_csv is for reading csv files, there's also read_excel, etc... with many adjustable parameters to match your file format\n",
    "df = pd.read_csv(file_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# head (tail) shows the first (last) 5 lines of the dataframe (unless you specify a number: e.g. df.tail(8))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Info shows you the types and non-missing counts of data in each column, plus memory usage\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what's up with the \"object\" columns??? Mixed types, usually!\n",
    "df[\n",
    "    \"PAYMENTS BY ISSUER\"\n",
    "].value_counts()  # This is WACK and a bad practice (mixing types, that is). Let's fix it!\n",
    "\n",
    "# we can fix it by reassigning the column using to_numeric (coerce makes non-numbers NaN)\n",
    "# pd.to_numeric(df.payments_by_issuer, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is a way to get the unique non-numeric values...\n",
    "\"\"\"\n",
    "Breaking this down:\n",
    "df['PAYMENTS BY ISSUER']: our column\n",
    "pd.to_numeric(df['PAYMENTS BY ISSUER'], errors='coerce').isnull(): tries to convert to number, null if not, returns true for isnull\n",
    "['PAYMENTS BY ISSUER'].unique(): grabbing unique values from our original column\n",
    "\"\"\"\n",
    "\n",
    "# let's add this to our read_csv instead (see top) along with specific dtypes\n",
    "na_values = df[\"PAYMENTS BY ISSUER\"][\n",
    "    pd.to_numeric(df[\"PAYMENTS BY ISSUER\"], errors=\"coerce\").isnull()\n",
    "].unique()\n",
    "\n",
    "# we can add a list of na_values as well as a dict of dtypes\n",
    "df = pd.read_csv(\n",
    "    file_location, na_values=na_values, dtype={\"PAYMENTS BY ISSUER\": \"float64\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looks as expected now!\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning up column names and values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's clean up these column names\n",
    "col_rename = {\n",
    "    \"REPORTING YEAR\": \"year\",\n",
    "    \"INSTITUTION OR ORGANIZATION\": \"institution\",\n",
    "    \"TYPE OF INSTITUTION OR ORGANIZATION\": \"institution_type\",\n",
    "    \"CREDIT CARD ISSUER\": \"issuer\",\n",
    "    \"CITY\": \"city\",\n",
    "    \"STATE\": \"state\",\n",
    "    \"STATUS\": \"status\",\n",
    "    \"IN EFFECT AS OF BEGINNING OF NEXT YEAR\": \"in_effect_ny\",\n",
    "    \"TOTAL OPEN ACCOUNTS AS OF END OF REPORTING YEAR\": \"total_open_acct_eoy\",\n",
    "    \"PAYMENTS BY ISSUER\": \"payments_by_issuer\",\n",
    "    \"NEW ACCOUNTS OPENED IN REPORTING YEAR\": \"new_acct_ry\",\n",
    "}\n",
    "\n",
    "# rename columns like so, using inplace=True to modify your existing df, inplace=False returns a new df\n",
    "df.rename(columns=col_rename, inplace=True)\n",
    "\n",
    "# note this won't complain if you spell something wrong, so always good to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# much better!\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GroupBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"state\"]).agg({\"new_acct_ry\": \"sum\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You usually end up having to fix data issues as-you-go, so make sure you go back and update prior code as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's fix Texas and Utah and Massachusetts using the replace method and a dict {\"original\": \"new\"}\n",
    "df.state = df.state.replace({\"Texas\": \"TX\", \"Utah\": \"UT\", \"Ma\": \"MA\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise:  Top 10 States by new accounts opened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's sort the results this time\n",
    "df.groupby([\"state\"]).agg({\"new_acct_ry\": \"sum\"}).sort_values(\n",
    "    by=\"new_acct_ry\", ascending=False\n",
    ").head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's make a chart of the top 10 states\n",
    "state_new_accounts = (\n",
    "    df.groupby([\"state\"])\n",
    "    .agg({\"new_acct_ry\": \"sum\"})\n",
    "    .sort_values(by=\"new_acct_ry\", ascending=False)\n",
    "    .reset_index()\n",
    "    .head(10)\n",
    ")\n",
    "\n",
    "# let's use seaborn barplot (you need to provide a df, and names of x and y axes)\n",
    "sns.barplot(data=state_new_accounts, x=\"state\", y=\"new_acct_ry\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: Make a plot of total_open_acct_eoy by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's make a chart of the top 10 states\n",
    "year_new_accounts = (\n",
    "    df.groupby([\"year\"])\n",
    "    .agg({\"total_open_acct_eoy\": \"sum\"})\n",
    "    .sort_values(by=\"total_open_acct_eoy\", ascending=False)\n",
    "    .reset_index()\n",
    "    .head(10)\n",
    ")\n",
    "\n",
    "# let's use seaborn pointplot (you need to provide a df, and names of x and y axes)\n",
    "sns.pointplot(data=year_new_accounts, x=\"year\", y=\"total_open_acct_eoy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby with multiple aggregation functions and sorting multi-index\n",
    "df.groupby([\"state\"]).agg({\"new_acct_ry\": [\"sum\", \"count\"]}).sort_values(\n",
    "    [(\"new_acct_ry\", \"sum\")], ascending=False\n",
    ").head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying and indexing\n",
    "\n",
    "There are many ways to filter and select data in pandas, query is best if you want to use an expression, indices are best for specifying columns and rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can use string methods to filter text columns (startswith, contains, endswith)\n",
    "df.query(\"institution.str.contains('City College')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can use string methods to filter text columns (startswith, contains, endswith)\n",
    "df.query(\"institution.str.contains('Rutgers') and year > 2016\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can use string methods to filter text columns (startswith, contains, endswith)\n",
    "df.query(\"year == 2015 and city == 'New York'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can get the same result with indexing and booleans but I think this is more annoying to type and read\n",
    "df[(df[\"year\"] == 2015) & (df[\"city\"] == \"New York\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iloc is your friend if you want to select data by position i.e. column or row number\n",
    "# here we are selecting ranges of columns and rows, i.e. df.iloc[rows,columns]\n",
    "df.iloc[2:8, 3:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method chaining\n",
    "\n",
    "It's easy to make mistakes in notebooks by running cells out of order. One way I like to keep my code clean is by using method chaining in a single cell instead of spreading code out over several cells. This allows us to combine multiple dataframe methods in a pipeline of sorts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: top ten cities in Texas according to sum of \"payments by issuer\"\n",
    "df.query(\"state == 'TX'\").groupby(\"city\").agg(\n",
    "    {\"payments_by_issuer\": \"sum\"}\n",
    ").sort_values(\"payments_by_issuer\", ascending=False).iloc[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
